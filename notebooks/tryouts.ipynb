{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0da5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "611e8518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "    \"error\":\"the query cannot be answered using the available datasets\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "question = input(\"Enter your query: \")\n",
    "prompt = f\"\"\" You are a data analyst.\n",
    "\n",
    "There are 3 datasets and user will ask questions based on these datasets:\n",
    "- sample_bo_tbl_large.csv: country (a 3 digit code like \"AAA\"), date, total_mins, international_mins, sms, total_data_usage, payg_amount\n",
    "- sample_sub_details_large.csv: country, channel, date, subs, netadds, churn\n",
    "- sample_revenue_large.csv: country, channel, date, revenue, net_revenue\n",
    "\n",
    "Your task:\n",
    "- Identify relevant datasets (with alias)\n",
    "- Suggest joins (if needed): left, right, on, how\n",
    "- Provide filters as list of {{\"column\": \"...\", \"operator\": \"...\", \"value\": ...}}\n",
    "- Indicate aggregation type (\"sum\", \"mean\", \"correlation\", etc.)\n",
    "- List involved columns\n",
    "\n",
    "Your response should be only a JSON in the following format which will be an input as parameters to a method which performs these operations using pandas:\n",
    "{{\n",
    "  \"datasets\": [\"name\":..., \"alias\":...],\n",
    "  \"joins\": [...],\n",
    "  \"filters\": [...],\n",
    "  \"aggregation\": \"...\",\n",
    "  \"columns\": [...]\n",
    "}}\n",
    "If there is a date in the filters convert it into relevant dates of format dd-mm-yyyy and add it to the JSON.\n",
    "Think step by step and then form the params JSON.\n",
    "Double check all the values before giving the response. Donot confuse between operators == and =.\n",
    "If the user asks queries that cannot be answered using the datasets, return a json in the following format:\n",
    "{{\n",
    "    \"error\":\"the query cannot be answered using the available datasets\"\n",
    "}}\n",
    "User Question: {question}\"\"\"\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4o\",\n",
    "    messages = [{\"role\":\"user\",\"content\":prompt}],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c6596885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine the country with the highest churn-to-subscriber ratio in Q1, we need to work with the `sample_sub_details_large.csv` dataset. We will filter the data for Q1, calculate the churn-to-subscriber ratio for each country, and then find the country with the maximum ratio.\n",
      "\n",
      "Here's the SQL query:\n",
      "\n",
      "```sql\n",
      "SELECT country, MAX(churn_ratio) AS max_churn_ratio\n",
      "FROM (\n",
      "    SELECT country, SUM(churn) / SUM(subs) AS churn_ratio\n",
      "    FROM sample_sub_details_large\n",
      "    WHERE strftime('%m', date) IN ('01', '02', '03')\n",
      "    GROUP BY country\n",
      ")\n",
      "LIMIT 1;\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "client = OpenAI()\n",
    "question = input(\"Enter your query: \")\n",
    "prompt = f\"\"\" You are a data analyst.\n",
    "\n",
    "There are 3 datasets and user will ask questions based on these datasets:\n",
    "- sample_bo_tbl_large.csv: country (a 3 digit code like \"AAA\"), date, total_mins, international_mins, sms, total_data_usage, payg_amount\n",
    "- sample_sub_details_large.csv: country, channel, date, subs, netadds, churn\n",
    "- sample_revenue_large.csv: country, channel, date, revenue, net_revenue\n",
    "\n",
    "Your task is to generate an SQLite-compatible SQL query to answer the user question.\n",
    "Think step by step and then formulate the query. Do not add any comments in the query.\n",
    "Maintain consistensy in your query generation pattern and generate as simple query as possible for a given question.\n",
    "If the query cannot be answered from the available datasets, just respond with \"Query out of available data range.\"\n",
    "User Question: {question}\"\"\"\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4o\",\n",
    "    messages = [{\"role\":\"user\",\"content\":prompt}],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "18e1ff98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT country, MAX(churn_ratio) AS max_churn_ratio\n",
      "FROM (\n",
      "    SELECT country, SUM(churn) / SUM(subs) AS churn_ratio\n",
      "    FROM sample_sub_details_large\n",
      "    WHERE strftime('%m', date) IN ('01', '02', '03')\n",
      "    GROUP BY country\n",
      ")\n",
      "LIMIT 1;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql=response.choices[0].message.content.split(\"```\")[1][4:]\n",
    "print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f25886f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\Documents\\lycaassignment\\db\\data.db\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def load_csvs_to_sqlite(db_path):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    # Load each CSV\n",
    "    bo_df = pd.read_csv('../data/sample_bo_tbl_large.csv')\n",
    "    bo_df.to_sql('sample_bo_tbl_large', conn, if_exists='replace', index=False)\n",
    "\n",
    "    sub_df = pd.read_csv('../data/sample_sub_details_large.csv')\n",
    "    sub_df.to_sql('sample_sub_details_large', conn, if_exists='replace', index=False)\n",
    "\n",
    "    rev_df = pd.read_csv('../data/sample_revenue_large.csv')\n",
    "    rev_df.to_sql('sample_revenue_large', conn, if_exists='replace', index=False)\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "db_path = os.path.abspath(\"../db/data.db\")\n",
    "print(db_path)\n",
    "load_csvs_to_sqlite(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "720da965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def run_sql(db_path, sql):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(sql)\n",
    "    rows = cursor.fetchall()\n",
    "    conn.close()\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "09f6a674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT country, MAX(churn_to_subs_ratio) as max_ratio\n",
      "FROM (\n",
      "    SELECT country, SUM(churn) * 1.0 / SUM(subs) as churn_to_subs_ratio\n",
      "    FROM sample_sub_details_large \n",
      "    WHERE strftime('%m', date) IN ('01', '02', '03')\n",
      "    GROUP BY country\n",
      ")\n",
      "LIMIT 1;\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('BBB', 0.28573664277442173)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sql)\n",
    "run_sql(db_path=db_path,sql= sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "abb28fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in database:\n",
      "bo_table\n",
      "sub_table\n",
      "rev_table\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "\n",
    "conn = sqlite3.connect(db_path)  # adjust path to your db\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "print(\"Tables in database:\")\n",
    "for table in tables:\n",
    "    print(table[0])\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb969752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
